{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LuSRu90vhG9U"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "key=userdata.get('openai_key')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzCv4iZzXrAe",
        "outputId": "72d83a0c-005d-4449-d4f3-0b03dc4672d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28.1\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/77.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (4.66.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (3.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.1\n"
          ]
        }
      ],
      "source": [
        "#!pip install openai\n",
        "!pip install openai==0.28.1\n",
        "import openai\n",
        "openai.api_key = key\n",
        "\n",
        "def Generate_Content(question, model=\"gpt-3.5-turbo\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": question}]\n",
        "    openai_response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages\n",
        "    )\n",
        "    return openai_response.choices[0].message[\"content\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q127Y4DmJn_g",
        "outputId": "a0a74043-a7ac-4e53-da35-f545b4cddc78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alice falls down a rabbit hole and finds herself in a strange world filled with quirky characters and talking animals. She goes on a series of fantastical adventures and encounters the enigmatic Cheshire Cat, the Mad Hatter, and the tyrannical Queen of Hearts. Ultimately, Alice wakes up to find it was all a dream, leaving readers to ponder the nature of reality and imagination.\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Summarize Alice in the wonderland in 3 sentences\n",
        "\"\"\"\n",
        "\n",
        "prompt1 = f\"\"\"\n",
        "Write a program to check if a number is prime or not\n",
        "\"\"\"\n",
        "\n",
        "response = Generate_Content(prompt)\n",
        "print(response)\n",
        "\n",
        "f=open('response.txt','w')\n",
        "f.write(response)\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LZR11TLLdzO"
      },
      "source": [
        "### Prompt engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sxx_slyQG3s"
      },
      "source": [
        "**Deriving Inference**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNE9sHzcQVtu"
      },
      "outputs": [],
      "source": [
        "review = \"\"\"\n",
        "The cashier wasn't responding to me though i tried to contact\n",
        "him repeatedly. Also the product is overpriced.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64ljpvCSRRKb",
        "outputId": "7a5853a3-7fd4-4e89-c779-095663073406"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Negative\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "What is the sentiment in the product review,\n",
        "which is delimited with triple backticks?\n",
        "'''{review}'''\n",
        "\"\"\"\n",
        "response = Generate_Content(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LzFqeBORZDF",
        "outputId": "a893c916-ffe6-48bf-cb21-a556e5ae6e54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Frustration\n",
            "2. Disappointment\n",
            "3. Annoyance\n",
            "4. Dissatisfaction\n",
            "5. Unhappiness\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Identify the top five emotions conveyed in the product review,\n",
        "which is delimited with triple backticks?\n",
        "'''{review}'''\n",
        "\"\"\"\n",
        "response = Generate_Content(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mm9Rh7B7RdBT",
        "outputId": "fd180ebf-235a-48d0-e482-5524c9b18f84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yes, frustration is present in this product review as the customer mentions that the cashier was not responding to them and that the product is overpriced.\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Is frustration present in the product review,\n",
        "which is delimited with triple backticks?\n",
        "'''{review}'''\n",
        "\"\"\"\n",
        "response = Generate_Content(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_ndzo9xSgH_"
      },
      "source": [
        "**Expanding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqxNkattS2OR",
        "outputId": "6d021cfc-37f1-463c-ccae-9a4171c171ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dear valued customer,\n",
            "\n",
            "Thank you for taking the time to provide feedback on your recent experience with us. We sincerely appreciate your input as it helps us to improve our services. \n",
            "\n",
            "We apologize for any inconvenience you experienced with our cashier not responding to you promptly. Please be assured that we have addressed this with our team to ensure that all customers are attended to in a timely and efficient manner.\n",
            "\n",
            "Regarding the pricing of our products, we strive to offer competitive prices while maintaining the quality of our products. We will definitely take your feedback into consideration as we constantly review and adjust our pricing to better serve our customers.\n",
            "\n",
            "We value your business and hope that you will give us another chance to provide you with a positive shopping experience in the future. If you have any other concerns or feedback, please do not hesitate to reach out to us.\n",
            "\n",
            "Thank you once again for bringing this to our attention.\n",
            "\n",
            "Best regards,\n",
            "[Your Name]\n",
            "Customer Service Team\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Behave like a customer service agent.\n",
        "Generate a email to reply to the customer\n",
        "who provide the review , which is delimited\n",
        "with triple backticks.\n",
        "Thanks the customer first.  Apologize if the review is negative.\n",
        "Use details from the review and compose a response in a professional tone.\n",
        "'''{review}'''\n",
        "\"\"\"\n",
        "response = Generate_Content(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcARGNEUcACQ"
      },
      "source": [
        "**Moderation API**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-iGX5PDa0mc",
        "outputId": "126988c9-2161-44c6-b483-e178d26ce8f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categories: {\n",
            "  \"sexual\": false,\n",
            "  \"hate\": false,\n",
            "  \"harassment\": false,\n",
            "  \"self-harm\": false,\n",
            "  \"sexual/minors\": false,\n",
            "  \"hate/threatening\": false,\n",
            "  \"violence/graphic\": true,\n",
            "  \"self-harm/intent\": false,\n",
            "  \"self-harm/instructions\": false,\n",
            "  \"harassment/threatening\": false,\n",
            "  \"violence\": true\n",
            "}\n",
            "Category Scores: {\n",
            "  \"sexual\": 0.0032525891438126564,\n",
            "  \"hate\": 0.00027801719261333346,\n",
            "  \"harassment\": 0.011542389169335365,\n",
            "  \"self-harm\": 0.08207657188177109,\n",
            "  \"sexual/minors\": 6.938513979548588e-05,\n",
            "  \"hate/threatening\": 0.00044928607530891895,\n",
            "  \"violence/graphic\": 0.9097883701324463,\n",
            "  \"self-harm/intent\": 0.00121951790060848,\n",
            "  \"self-harm/instructions\": 0.0012101347092539072,\n",
            "  \"harassment/threatening\": 0.002760722767561674,\n",
            "  \"violence\": 0.9737570285797119\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "response = openai.Moderation.create(\n",
        "  input=\"Input text goes here while at war with intense gunfire ripping human limbs\"\n",
        ")\n",
        "\n",
        "categories = response['results'][0]['categories']\n",
        "category_scores = response['results'][0]['category_scores']\n",
        "\n",
        "print(\"Categories:\", categories)\n",
        "print(\"Category Scores:\", category_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NJDeJLIMV6e"
      },
      "source": [
        "**Different Roles**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eV4HGY1EMYzp"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are an astronomy expert.\"},\n",
        "    {\"role\": \"user\", \"content\": \"What is the 5th planet in solar system?\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"It is Jupiter\"},\n",
        "    {\"role\": \"user\", \"content\": \"What is the next planet?\"}\n",
        "  ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBT7DE5FPKf2",
        "outputId": "f54216fe-d360-4b23-9e02-b4b8aff20306"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The next planet after Jupiter is the 6th planet from the Sun, which is Saturn.\n"
          ]
        }
      ],
      "source": [
        "res=response['choices'][0]['message']['content']\n",
        "print(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYATZN1VXgdf"
      },
      "source": [
        "**Chaining Prompts**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_rJMhHX5oM2",
        "outputId": "02426c06-e7fd-41ab-d27d-1898c92f50d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: The user is asking about the Apple iPhone product which is listed for $200. \n",
            "Step 2: I'm sorry, but the Apple iPhone is available for $200 and not $150 as mentioned in your question. \n",
            "Step 3: The Apple iPhone will be shipped 3 days after the order is placed. Thank you for your inquiry.\n"
          ]
        }
      ],
      "source": [
        "question=\"\"\"Is Apple iphone available for $150?\"\"\"\n",
        "prompt = f\"\"\" Follow the below three steps to respond to question from customer\n",
        "which is delimited with triple backticks?'''{question}'''\n",
        "Use the following 3 steps and compose a concise answer:\n",
        "\n",
        "Step 1: If the user is asking about any of the products below move ahead.\n",
        "Otherwise proceed to step 3.\n",
        "1. Product: Apple iphone;   Price: $ 200\n",
        "2. Product: Samsung TV;   Price: $ 100\n",
        "3. Product: Sony Hometheater;   Price: $ 150\n",
        "Step 2: If the message contains products\n",
        "listed above, validate the assumption of user and inform if it is wrong\n",
        "Step 3: If the message contains products listed above, tell the user that\n",
        "product will be shipped 3 days after order.Otherwise mention that product\n",
        "doesn't exist currently.\"\"\"\n",
        "response = Generate_Content(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kqVsaV6KI3M"
      },
      "source": [
        "### Using LangChain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fsn6hJCcSz7K"
      },
      "source": [
        "**Using LangChain**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYdTeVYcRtyK",
        "outputId": "1b756dfd-dad2-4819-98bf-a924d7280d56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.2.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core\n",
            "  Downloading langchain_core-0.2.1-py3-none-any.whl (308 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m308.5/308.5 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.9.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n",
            "Collecting langchain<0.3.0,>=0.2.0 (from langchain-community)\n",
            "  Downloading langchain-0.2.0-py3-none-any.whl (973 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m973.7/973.7 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.2.0,>=0.1.0 (from langchain-community)\n",
            "  Downloading langsmith-0.1.62-py3-none-any.whl (122 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.3/122.3 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.3.0)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (2.7.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain<0.3.0,>=0.2.0->langchain-community)\n",
            "  Downloading langchain_text_splitters-0.2.0-py3-none-any.whl (23 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.0->langchain-community)\n",
            "  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain, langchain-community\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed dataclasses-json-0.6.6 jsonpatch-1.33 jsonpointer-2.4 langchain-0.2.0 langchain-community-0.2.0 langchain-core-0.2.1 langchain-text-splitters-0.2.0 langsmith-0.1.62 marshmallow-3.21.2 mypy-extensions-1.0.0 orjson-3.10.3 packaging-23.2 typing-inspect-0.9.0\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.6)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.1)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.0)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.62)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain) (2.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-community langchain-core\n",
        "!pip install --upgrade langchain\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "chat = ChatOpenAI(temperature=0.0, model=\"gpt-3.5-turbo\", openai_api_key=key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7Nv7BFGS4MG",
        "outputId": "f8735a48-2367-4fd4-bec8-70363dd0a74a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['style', 'text'], template='Translate the text that is delimited by triple backticks into a style that is {style}. text: ```{text}```\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "template_string = \"\"\"Translate the text \\\n",
        "that is delimited by triple backticks \\\n",
        "into a style that is {style}. \\\n",
        "text: ```{text}```\n",
        "\"\"\"\n",
        "\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_template(template_string)\n",
        "\n",
        "prompt_template.messages[0].prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Z3vWU5YuZwE"
      },
      "outputs": [],
      "source": [
        "customer_style = \"\"\"American English \\\n",
        "in a calm and respectful tone\n",
        "\"\"\"\n",
        "customer_email = \"\"\"\n",
        "Let's have a barbecue. G'day mate! Hey friend! Do you wanna\n",
        "hang out this arvo?\n",
        "\"\"\"\n",
        "customer_messages = prompt_template.format_messages(\n",
        "                    style=customer_style,\n",
        "                    text=customer_email)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5RxCNONTSXM",
        "outputId": "728dde96-1f5e-46a1-8349-5331052d61c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let's have a barbecue. Hello friend! Hey buddy! Do you want to hang out this afternoon?\n"
          ]
        }
      ],
      "source": [
        "customer_response = chat(customer_messages)\n",
        "print(customer_response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faIG-7zVsksk"
      },
      "source": [
        "**Managing Memory**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Without using memmory\n",
        "print(Generate_Content(\"My name is Alex\"))\n",
        "print(Generate_Content(\"How much is 1 kilogram?\"))\n",
        "print(Generate_Content(\"What is my name?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yf_mCIpnIQqB",
        "outputId": "3a740325-0ebc-449c-e0e4-be495cc59fd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello Alex! How can I assist you today?\n",
            "1 kilogram is equal to approximately 2.20462 pounds.\n",
            "I'm sorry, I cannot determine your name as I am an AI Assistant and do not have access to personal information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OG0QhKqVso9G"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "llm = ChatOpenAI(temperature=0.0, model=\"gpt-3.5-turbo\", openai_api_key=key)\n",
        "memory = ConversationBufferMemory()\n",
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory = memory,\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQitP8JtvWai",
        "outputId": "3bf5f14e-c855-469b-ad2a-26e7e4429028"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: My name is Alex\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: My name is Alex\n",
            "AI: Hello Alex! It's nice to meet you. How can I assist you today?\n",
            "Human: How much is 1 kilogram?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: My name is Alex\n",
            "AI: Hello Alex! It's nice to meet you. How can I assist you today?\n",
            "Human: How much is 1 kilogram?\n",
            "AI: 1 kilogram is equal to 1000 grams. It is a unit of mass in the metric system. Is there anything else you would like to know?\n",
            "Human: What is my name?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Human: My name is Alex\n",
            "AI: Hello Alex! It's nice to meet you. How can I assist you today?\n",
            "Human: How much is 1 kilogram?\n",
            "AI: 1 kilogram is equal to 1000 grams. It is a unit of mass in the metric system. Is there anything else you would like to know?\n",
            "Human: What is my name?\n",
            "AI: Your name is Alex.\n"
          ]
        }
      ],
      "source": [
        "conversation.predict(input=\"My name is Alex\")\n",
        "conversation.predict(input=\"How much is 1 kilogram?\")\n",
        "conversation.predict(input=\"What is my name?\")\n",
        "print(memory.buffer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqcC8r5_vjul",
        "outputId": "3925092a-bb0f-44fb-fd5a-ed8ffcd51418"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: I am Alex\n",
            "AI: Nice to meet you Alex\n"
          ]
        }
      ],
      "source": [
        "memory.load_memory_variables({})\n",
        "memory = ConversationBufferMemory()\n",
        "memory.save_context({\"input\": \"I am Alex\"},\n",
        "                    {\"output\": \"Nice to meet you Alex\"})\n",
        "print(memory.buffer)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}